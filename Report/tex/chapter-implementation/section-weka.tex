\section{Weka}
\label{sect:weka}
One of the most popular ways of drawing insights from data through machine
learning is by using a predefined library.  This is because the library takes
much of the technical effort out of the development.  All of the math behind the
machine learning is hidden behind the library and often there are nice user
interfaces or APIs associated with the library.  Typically, there are many
different methods that can be called to comb through the data to extract
insights and relationships about the data.  In the case of ProGENitor the Weka
library was chosen as it has an excellent Java API and access to many different
methods.  Choosing the method to extract information from the data requires some
knowledge about the data itself.  In this case, clustering was chosen as the
data is mostly nominal data and the goal is to define some grouping that leads
to the end goal.  To extract the data, first ProGENitor must generate an
Arrf file to feed into Weka and then Weka has to evaluate it with the clustering
classification.

\subsection{Arff Creation}
Weka uses the .arff file format to feed data into the Weka toolset.  The Arff
file contains two major sections.  These sections are the header section and the
data section \cite{arff}.  The header contains the name of the relation, a list
of attributes, and their types.  The data section contains the data that will
be used for machine learning.  A sample .arff file would look like the
following:\\*
\\*
\begin{tt}
\begin{footnotesize}
@relation education\\*
\\
@attribute degree \{PhD,Bachelors,Masters\}\\*
@attribute specialization
\{Electrical,Circuits,Analog,Computer\newline \indent Architecture,Digital\}\\*
@attribute goal \{true,false\}\\ \\* @data\\*
Bachelors,Electrical,false\\*
Masters,Circuits,false\\*
Bachelors,Electrical,true\\*
Masters,Circuits,true\\*
PhD,MSU,Digital,true\\*
\end{footnotesize}
\end{tt}

ProGENitor currently generates the .arff file containing just the educational
nodes.  One of the keys to getting quality insights out of Weka is controlling
the data being fed into the tools.  In this case, only the educational
data is fed into the tool.  This process could easily be replicated for additional
insights.  To generate the arff file, ProGENitor contains a Java method called
generate arff in the connections package.  This code follows the procedure
detailed in figure \ref{fig:arff generation} to generate the arff file that is
later used by Weka.

\usetikzlibrary{shapes,arrows,chains}

\begin{figure}[H]
	\centering
% Start the picture
\begin{tikzpicture}[%
    >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]
% ------------------------------------------------- 
% A few box styles 
% <on chain> *and* <on grid> reduce the need for manual relative
% positioning of nodes
\tikzset{
  base/.style={draw, on chain, on grid, align=center, minimum height=4ex},
  proc/.style={base, rectangle, text width=8em},
  test/.style={base, diamond, aspect=2, text width=5em},
  % Connector line styles for different parts of the diagram
  norm/.style={->, draw},
  it/.style={font={\small\itshape}}
}
% -------------------------------------------------
% Start by placing the nodes
\node [proc] (p0) {Setup Header and write it to .arff file};
% Use join to connect a node to the previous one 
\node [proc, join] (p1) {Pull in database headers};
\node [proc, join] (p2) {Establish list of attributes};
\node [proc, join] (p3) {Collect all possible values from user data};
\node [proc, join] (p4) {Write attribute values to .arff file}; 
\node [proc, join] (p5) {Pull data associated with each attribute};
\node [proc, join] (p6) {Write data line to .arff file};

\draw [->, dotted, thick, shorten >=1mm]
  (p4.south) -- ++(50mm,-3mm)  -- ++(27mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {For each attribute} (p3);

\draw [->, dotted, thick, shorten >=1mm]
  (p6.south) -- ++(50mm,-3mm)  -- ++(27mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {For each line of user data} (p5);

% -------------------------------------------------
\end{tikzpicture}
	\caption{Arff File Generation}
	\label{fig:arff generation}
\end{figure}

\subsection{Clustering}
One major advantage to using the Weka library is it takes complex code and makes
it relatively simple.  As seen in Figure \ref{fig:clustering}, the process that is
followed to analyze the data in the Arrf file is very simple and straight
forward.  Once the Weka jar is imported into the project, the code is very quick
to implement, as good documentation is available for the API \cite{weka}.  The
complex portion of work is then ensuring that the appropriate classification is
applied and the data is parsed in a useful fashion.


\usetikzlibrary{shapes,arrows,chains}

\begin{figure}[H]
	\centering
% Start the picture
\begin{tikzpicture}[%
    >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]
% ------------------------------------------------- 
% A few box styles 
% <on chain> *and* <on grid> reduce the need for manual relative
% positioning of nodes
\tikzset{
  base/.style={draw, on chain, on grid, align=center, minimum height=4ex},
  proc/.style={base, rectangle, text width=8em},
  test/.style={base, diamond, aspect=2, text width=5em},
  % Connector line styles for different parts of the diagram
  norm/.style={->, draw},
  it/.style={font={\small\itshape}}
}
% -------------------------------------------------
% Start by placing the nodes
\node [proc] (p0) {Read in Arff File};
% Use join to connect a node to the previous one 
\node [proc, join] (p1) {Setup Cluster Evaluation};
\node [proc, join] (p2) {Evaluate Arff Data Using Cluster Method};
\node [proc, join] (p3) {Parse and Return Results};
% -------------------------------------------------
\end{tikzpicture}
	\caption{High Level Data Clustering}
	\label{fig:clustering}
\end{figure}

In the case of ProGENitor, EM (expectation maximization) clustering was chosen
as it automatically determines the number of clusters required through cross
validation.  The algorithm that EM follows is shown in figure
\ref{fig:EM} \cite{EM}.  EM differs from other clustering algorithms in that it
uses probability of cluster membership instead of a distance method used by
other clustering methods such as k-mean clustering.  EM starts with one cluster,
then cross validates the data and applies the probability of cluster membership
classification.  It then calculates the log-likelihood for the set and if it
increases, creates a new cluster and starts over.  It repeats this process until
the log likelihood no longer increases.  The left over clusters will then be
returned as the results.

\begin{figure}[H]
	\centering
% Start the picture
\begin{tikzpicture}[%
    >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]
% ------------------------------------------------- 
% A few box styles 
% <on chain> *and* <on grid> reduce the need for manual relative
% positioning of nodes
\tikzset{
  base/.style={draw, on chain, on grid, align=center, minimum height=4ex},
  proc/.style={base, rectangle, text width=8em},
  test/.style={base, diamond, aspect=2, text width=5em},
  % Connector line styles for different parts of the diagram
  norm/.style={->, draw},
  it/.style={font={\small\itshape}}
}
% -------------------------------------------------
% Start by placing the nodes
\node [proc] (p0) {Set \# of\newline Clusters to 1};
% Use join to connect a node to the previous one 
\node [proc, join] (p1) {Split Training Set into 10 Equal Sets};
\node [proc, join] (p2) {Cross Validate, Using 1 Set for Testing and 9 Sets
for Data}; 
\node [proc, join] (p3) {EM Assigns Probability Distribution to Each
Instance}; 
\node [proc, join] (p4) {Log Likelihood Averaged Over All 10 Runs};
\node [test, join] (p5) {IF Log Likelihood Has Increased, Increment Clusters by
1};

\draw [->, dotted, thick, shorten >=1mm]
  (p3.east) -- ++(35mm,0mm)  -- ++(40mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    [above]{Change Set used for Testing.}
    (p2);
\draw [->, dotted, thick, shorten >=1mm]
  (p3.east) -- ++(35mm,0mm)  -- ++(40mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {Repeat Until All Sets Used for Testing.}
    (p2);

\draw [->, dotted, thick, shorten >=1mm]
  (p5.east) -- ++(20mm,0mm)  -- ++(27mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {} (p0);
% -------------------------------------------------
\end{tikzpicture}
	\caption{EM Clustering Algorithm}
	\label{fig:EM}
\end{figure}
