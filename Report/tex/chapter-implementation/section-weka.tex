\section{Weka}
\label{sect:weka}
One of the most popular ways of drawing insights from data through machine
learning is by using a predefined library.  This is because the library takes
much of the technical effort out of the development.  All of the math behind the
machine learning is hidden behind the library and often there are nice user
interfaces or APIs associated with the library.  Typically, there are many
different methods that can be called to comb through the data to extract
insights and relationships about the data.  In the case of ProGENitor the Weka
library was chosen as it has an excellent API and access to many different
methods.  Choosing the method to extract information from the data requires some
knowledge about the data itself.  In this case, clustering was chosen as the
data is mostly nominal data and the goal is to define some grouping that leads
to the end goal.  To extract the data, first ProGENitor must generate a data
file to feed into Weka.  Then Weka has to evaluate it with the chosen
classification, which in ProGENitor's case is clustering.

\subsection{Weka Data File Creation}
Weka uses the .arff file format to feed data into the Weka tool set.  The arff
file contains two major sections.  These sections are the header section and the
data section \cite{arff}.  The header contains the name of the relation, a list
of attributes, and their types.  The data section contains the data that will
be used for machine learning.  A sample .arff file would look like the
following:\\*
\\*
\begin{tt}
\begin{footnotesize}
@relation education\\*
\\
@attribute degree \{PhD,Bachelors,Masters\}\\*
@attribute specialization
\{Electrical,Circuits,Analog,Computer\newline \indent Architecture,Digital\}\\*
@attribute goal \{true,false\}\\ \\* @data\\*
Bachelors,Electrical,false\\*
Masters,Circuits,false\\*
Bachelors,Electrical,true\\*
Masters,Circuits,true\\*
PhD,MSU,Digital,true\\*
\end{footnotesize}
\end{tt}

ProGENitor currently generates the .arff file containing just the educational
nodes.  One of the keys to getting quality insights out of Weka is controlling
the data being fed into the tools.  In this case, only the educational
data is fed into the tool.  This process could easily be replicated for additional
insights.  ProGENitor contains a method that follows the procedure detailed in
figure \ref{fig:arff generation} to generate the data file that is later used by
Weka.

\usetikzlibrary{shapes,arrows,chains}

\begin{figure}[H]
	\centering
% Start the picture
\begin{tikzpicture}[%
    >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]
% ------------------------------------------------- 
% A few box styles 
% <on chain> *and* <on grid> reduce the need for manual relative
% positioning of nodes
\tikzset{
  base/.style={draw, on chain, on grid, align=center, minimum height=4ex},
  proc/.style={base, rectangle, text width=8em},
  test/.style={base, diamond, aspect=2, text width=5em},
  % Connector line styles for different parts of the diagram
  norm/.style={->, draw},
  it/.style={font={\small\itshape}}
}
% -------------------------------------------------
% Start by placing the nodes
\node [proc] (p0) {Setup file header and write it to Weka data file};
% Use join to connect a node to the previous one 
\node [proc, join] (p1) {Pull in database headers};
\node [proc, join] (p2) {Establish list of attributes based on headers};
\node [proc, join] (p3) {Collect all possible values from user data};
\node [proc, join] (p4) {Write attribute values to Weka data file}; 
\node [proc, join] (p5) {Extract data associated with each attribute from
database}; 
\node [proc, join] (p6) {Write extracted data line to Weka data file};

\draw [->, dotted, thick, shorten >=1mm]
  (p4.south) -- ++(50mm,-3mm)  -- ++(27mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {For each attribute} (p3);

\draw [->, dotted, thick, shorten >=1mm]
  (p6.south) -- ++(50mm,-3mm)  -- ++(27mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {For each line of user data} (p5);

% -------------------------------------------------
\end{tikzpicture}
	\caption{Weka Data File Generation}
	\label{fig:arff generation}
\end{figure}

\subsection{Clustering}
One major advantage to using the Weka library is it takes complex code and makes
it relatively simple.  As seen in Figure \ref{fig:clustering}, the process that is
followed to analyze the data in the Weka data file is very simple and straight
forward.  Once the Weka library is imported into the project, the code is very
quick to implement, as good documentation is available for the API \cite{weka}.  The
complex portion of work is then ensuring that the appropriate classification is
applied and the data is parsed in a useful fashion.


\usetikzlibrary{shapes,arrows,chains}

\begin{figure}[H]
	\centering
	\resizebox {!} {55mm} {
% Start the picture
\begin{tikzpicture}[%
    >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]
% ------------------------------------------------- 
% A few box styles 
% <on chain> *and* <on grid> reduce the need for manual relative
% positioning of nodes
\tikzset{
  base/.style={draw, on chain, on grid, align=center, minimum height=4ex},
  proc/.style={base, rectangle, text width=8em},
  test/.style={base, diamond, aspect=2, text width=5em},
  % Connector line styles for different parts of the diagram
  norm/.style={->, draw},
  it/.style={font={\small\itshape}}
}
% -------------------------------------------------
% Start by placing the nodes
\node [proc] (p0) {Read in Data File};
% Use join to connect a node to the previous one 
\node [proc, join] (p1) {Analyze Data in Data File, Cluster Data Using Weka};
\node [proc, join] (p2) {Parse and Return Results};
% -------------------------------------------------
\end{tikzpicture}
}
	\caption{High Level Data Clustering}
	\label{fig:clustering}
\end{figure}

The Weka data analysis can take many different forms as there are many different
classifications that can be applied.  In the case of ProGENitor, EM (expectation
maximization) clustering was chosen as it automatically determines the number of
clusters required through cross validation.  The algorithm that EM follows is
shown in figure \ref{fig:EM} \cite{EM}.  EM differs from other clustering
algorithms in that it uses probability of cluster membership instead of a
distance method used by other clustering methods such as k-mean clustering.  EM
starts with one cluster, then cross validates the data and applies the
probability of cluster membership classification.  It then calculates the
log-likelihood for the set and if it increases, creates a new cluster and starts
over.  It repeats this process until the log likelihood no longer increases. 
The left over clusters will then be returned as the results.

\begin{figure}[H]
	\centering
	\resizebox {!} {130mm} {
% Start the picture
\begin{tikzpicture}[%
    >=triangle 60,              % Nice arrows; your taste may be different
    start chain=going below,    % General flow is top-to-bottom
    node distance=6mm and 60mm, % Global setup of box spacing
    every join/.style={norm},   % Default linetype for connecting boxes
    ]
% ------------------------------------------------- 
% A few box styles 
% <on chain> *and* <on grid> reduce the need for manual relative
% positioning of nodes
\tikzset{
  base/.style={draw, on chain, on grid, align=center, minimum height=4ex},
  proc/.style={base, rectangle, text width=8em},
  test/.style={base, diamond, aspect=2, text width=5em},
  % Connector line styles for different parts of the diagram
  norm/.style={->, draw},
  it/.style={font={\small\itshape}}
}
% -------------------------------------------------
% Start by placing the nodes
\node [proc] (p0) {Set \# of\newline Clusters to 1};
% Use join to connect a node to the previous one 
\node [proc, join] (p1) {Split Training Set into 10 Equal Sets};
\node [proc, join] (p2) {Cross Validate, Using 1 Set for Testing and 9 Sets
for Data}; 
\node [proc, join] (p3) {EM Assigns Probability Distribution to Each
Instance}; 
\node [proc, join] (p4) {Log Likelihood Averaged Over All 10 Runs};
\node [test, join] (p5) {IF Log Likelihood Has Increased, Increment Clusters by
1};

\draw [->, dotted, thick, shorten >=1mm]
  (p3.east) -- ++(35mm,0mm)  -- ++(40mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    [above]{Change Set used for Testing.}
    (p2);
\draw [->, dotted, thick, shorten >=1mm]
  (p3.east) -- ++(35mm,0mm)  -- ++(40mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {Repeat Until All Sets Used for Testing.}
    (p2);

\draw [->, dotted, thick, shorten >=1mm]
  (p5.east) -- ++(20mm,0mm)  -- ++(27mm,0) 
  |- node [black, near end, yshift=0.75em, it]
    {} (p0);
% -------------------------------------------------
\end{tikzpicture}
}
	\caption{EM Clustering Algorithm}
	\label{fig:EM}
\end{figure}
